{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1VuYypV8m-Akz4b8d3vpMHcjJawLaNXZY","authorship_tag":"ABX9TyPdqGnLm/XN/e6zGyqiltQa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"wcNkVthASGBX","executionInfo":{"status":"ok","timestamp":1682792296742,"user_tz":-120,"elapsed":3096,"user":{"displayName":"Mohammad Amin Abbaszadeh","userId":"15130678173456026801"}}},"outputs":[],"source":["import pickle as pkl\n","from sklearn.preprocessing import StandardScaler\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","with open('/content/drive/MyDrive/Dataset_without_memory/dataset.pickle', 'rb') as f:\n","    dataset = pkl.load(f)\n","\n","with open('/content/drive/MyDrive/Dataset_without_memory/labels.pickle', 'rb') as f:\n","    labels = pkl.load(f)\n","\n","dataset.shape , labels.shape\n","\n","labels = labels['5m class']\n","dataset = dataset.iloc[: , 1:]\n","\n","import numpy as np\n","index1 = int(len(dataset) * 5/9)\n","index2 = int (len(dataset) * 6/9)\n","\n","\n","dataset_train , y_train  = np.asarray(dataset[: index1]).astype('float32') , np.asarray(labels[:index1 ]).astype('float32')\n","\n","dataset_val , y_val = np.asarray(dataset[index1 : index2 ]).astype('float32') , np.asarray(labels[index1 : index2]).astype('float32')\n","\n","dataset_test , y_test = np.asarray(dataset[index2 :  ]).astype('float32') , np.asarray(labels[index2:]).astype('float32')\n","\n","\n","\n","def standardization( dataframe1, dataframe2, dataframe3  ):\n","  ###we start the for loop form the second column because the first column is timesteps \n","  for i in range (dataframe1.shape[1]):\n","    \n","    retrn_data = dataframe1[:, i].reshape(-1, 1)\n","\n","    scaler = StandardScaler()\n","    retrn_data_standardized = scaler.fit_transform(retrn_data)\n","\n","    dataframe1[: , i] = retrn_data_standardized.flatten()\n","\n","\n","##########validation data\n","    retrn_data = dataframe2[:, i].reshape(-1, 1)\n","\n","    retrn_data_standardized = scaler.transform(retrn_data)\n","\n","    dataframe2[: , i] = retrn_data_standardized.flatten()\n","\n","##########test data\n","\n","    retrn_data = dataframe3[:, i].reshape(-1, 1)\n","\n","    retrn_data_standardized = scaler.transform(retrn_data)\n","\n","    dataframe3[: , i] = retrn_data_standardized.flatten()\n","\n","\n","\n","\n","  return dataframe1 , dataframe2, dataframe3\n","\n","X_train , X_val , X_test = standardization(dataset_train , dataset_val , dataset_test)\n"]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# define the random forest classifier with minimum fraction of instances per leaf = 20%\n","rf = RandomForestClassifier(n_estimators=100, min_samples_leaf=0.2)\n","\n","# train the random forest model on the training data\n","rf.fit(X_train, y_train)\n","\n","# predict on the validation data\n","y_pred_val = rf.predict(X_val)\n","\n","# evaluate the accuracy of the model on the validation data\n","accuracy_val = accuracy_score(y_val, y_pred_val)\n","\n","# predict on the test data\n","y_pred_test = rf.predict(X_test)\n","\n","# evaluate the accuracy of the model on the test data\n","accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","# print the accuracy on the validation and test data\n","print(\"Validation accuracy:\", accuracy_val)\n","print(\"Test accuracy:\", accuracy_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8b2fTlLS-g7","executionInfo":{"status":"ok","timestamp":1682792314111,"user_tz":-120,"elapsed":12388,"user":{"displayName":"Mohammad Amin Abbaszadeh","userId":"15130678173456026801"}},"outputId":"43cd7c36-9c42-4118-cb07-648226bb0274"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation accuracy: 0.5102090584609927\n","Test accuracy: 0.5075081288796925\n"]}]}]}