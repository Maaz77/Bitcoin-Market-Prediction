{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1LfzfHf-1z94qI9Te7rZ-QAV1Cg6Dv82r","authorship_tag":"ABX9TyNmaiLEHhw/e5Xwr1cF2L+0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"EWuRCZkLLn8i","executionInfo":{"status":"ok","timestamp":1682795441359,"user_tz":-120,"elapsed":4791,"user":{"displayName":"Mohammad Amin Abbaszadeh","userId":"15130678173456026801"}}},"outputs":[],"source":["import pickle as pkl\n","from sklearn.preprocessing import StandardScaler\n","\n","with open('/content/drive/MyDrive/Dataset_without_memory/dataset.pickle', 'rb') as f:\n","    dataset = pkl.load(f)\n","\n","with open('/content/drive/MyDrive/Dataset_without_memory/labels.pickle', 'rb') as f:\n","    labels = pkl.load(f)\n","\n","\n","\n","labels = labels['15m class']\n","dataset = dataset.iloc[: , 1:]\n","\n","import numpy as np\n","index1 = int(len(dataset) * 5/9)\n","index2 = int (len(dataset) * 6/9)\n","\n","\n","dataset_train , labels_train  = np.asarray(dataset[: index1]).astype('float32') , np.asarray(labels[:index1 ]).astype('float32')\n","\n","dataset_val , labels_val = np.asarray(dataset[index1 : index2 ]).astype('float32') , np.asarray(labels[index1 : index2]).astype('float32')\n","\n","dataset_test , labels_test = np.asarray(dataset[index2 :  ]).astype('float32') , np.asarray(labels[index2:]).astype('float32')\n","\n","\n","\n","def standardization( dataframe1, dataframe2, dataframe3  ):\n","  ###we start the for loop form the second column because the first column is timesteps \n","  for i in range (dataframe1.shape[1]):\n","    \n","    retrn_data = dataframe1[:, i].reshape(-1, 1)\n","\n","    scaler = StandardScaler()\n","    retrn_data_standardized = scaler.fit_transform(retrn_data)\n","\n","    dataframe1[: , i] = retrn_data_standardized.flatten()\n","\n","\n","##########validation data\n","    retrn_data = dataframe2[:, i].reshape(-1, 1)\n","\n","    retrn_data_standardized = scaler.transform(retrn_data)\n","\n","    dataframe2[: , i] = retrn_data_standardized.flatten()\n","\n","##########test data\n","\n","    retrn_data = dataframe3[:, i].reshape(-1, 1)\n","\n","    retrn_data_standardized = scaler.transform(retrn_data)\n","\n","    dataframe3[: , i] = retrn_data_standardized.flatten()\n","\n","\n","\n","\n","  return dataframe1 , dataframe2, dataframe3\n","\n","X_train , X_val , X_test = standardization(dataset_train , dataset_val , dataset_test)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYElLhnOq1kM","executionInfo":{"status":"ok","timestamp":1682782805394,"user_tz":-120,"elapsed":10655,"user":{"displayName":"Mohammad Amin Abbaszadeh","userId":"15130678173456026801"}},"outputId":"fec9fe95-a5f9-4b4a-9d54-ba1f8d1145fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","\n","\n","class_weights = compute_class_weight(\n","                                        class_weight = \"balanced\",\n","                                        classes = np.unique ( np.reshape( labels_train , (np.shape(labels_train)[0]))),\n","                                        y = np.reshape(labels_train ,(np.shape(labels_train)[0]))                                                 \n","                                    )\n","class_weights = dict(zip(np.unique(np.reshape(labels_train ,(np.shape(labels_train)[0]))), class_weights))\n","class_weights\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onX7-wYSqlQM","executionInfo":{"status":"ok","timestamp":1682795448775,"user_tz":-120,"elapsed":662,"user":{"displayName":"Mohammad Amin Abbaszadeh","userId":"15130678173456026801"}},"outputId":"f1bb43a8-689f-46d7-ff10-016e4117777f"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0.0: 1.0215744892874938, 1.0: 0.9793179212839129}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","\n","# Create the logistic regression model\n","logreg = LogisticRegression(class_weight=class_weights)\n","\n","# Train the model using the training data\n","logreg.fit(X_train, labels_train.ravel())\n","\n","# Use the model to make predictions on the validation data\n","y_pred = logreg.predict(X_val)\n","\n","# Calculate the accuracy of the model on the validation data\n","accuracy = accuracy_score(labels_val, y_pred)\n","\n","# Print the accuracy\n","print(\"Accuracy on validation data:\", accuracy)\n","\n","# Use the model to make predictions on the test data\n","y_pred_test = logreg.predict(X_test)\n","\n","# Calculate the accuracy of the model on the test data\n","accuracy_test = accuracy_score(labels_test, y_pred_test)\n","\n","# Print the accuracy\n","print(\"Accuracy on test data:\", accuracy_test)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uyl5VQLMjhF","executionInfo":{"status":"ok","timestamp":1682795455408,"user_tz":-120,"elapsed":879,"user":{"displayName":"Mohammad Amin Abbaszadeh","userId":"15130678173456026801"}},"outputId":"2d908827-0d93-491e-ac01-17e761c614b7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on validation data: 0.5349945684705256\n","Accuracy on test data: 0.5309193023943246\n"]}]}]}